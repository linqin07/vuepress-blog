(window.webpackJsonp=window.webpackJsonp||[]).push([[80],{306:function(a,s,t){"use strict";t.r(s);var e=t(2),r=Object(e.a)({},(function(){var a=this,s=a.$createElement,t=a._self._c||s;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h4",{attrs:{id:"_1-下载"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-下载","aria-hidden":"true"}},[a._v("#")]),a._v(" 1.下载")]),a._v(" "),t("p",[t("a",{attrs:{href:"http://kafka.apache.org/downloads",target:"_blank",rel:"noopener noreferrer"}},[a._v("下载二进制包"),t("OutboundLink")],1)]),a._v(" "),t("p",[t("img",{attrs:{src:"https://blog-07.oss-cn-guangzhou.aliyuncs.com/picBak/1551084352010.png",alt:"1551084352010.png"}})]),a._v(" "),t("h4",{attrs:{id:"_2-解压"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-解压","aria-hidden":"true"}},[a._v("#")]),a._v(" 2.解压")]),a._v(" "),t("blockquote",[t("p",[a._v("tar -zxvf kafka_2.11-2.1.1.tgz")])]),a._v(" "),t("h4",{attrs:{id:"_3-配置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-配置","aria-hidden":"true"}},[a._v("#")]),a._v(" 3.配置")]),a._v(" "),t("p",[a._v("基本上都使用默认，修改一下kafka自身的地址，zk连接的地址即可。")]),a._v(" "),t("blockquote",[t("p",[a._v("listeners=PLAINTEXT://:9092")]),a._v(" "),t("p",[a._v("zookeeper.connect=localhost:2181")])]),a._v(" "),t("h4",{attrs:{id:"_4-使用默认的zk"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-使用默认的zk","aria-hidden":"true"}},[a._v("#")]),a._v(" 4.使用默认的zk")]),a._v(" "),t("p",[a._v("ps：最好不要用kafka自带的，可以先搭建好zookeeper集群")]),a._v(" "),t("p",[a._v("启动：")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("./bin/zookeeper-server-start.sh config/zookeeper.properties "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("&")]),a._v(" \n")])])]),t("h4",{attrs:{id:"_5-配置详解"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-配置详解","aria-hidden":"true"}},[a._v("#")]),a._v(" 5.配置详解")]),a._v(" "),t("p",[a._v("具体参考：https://www.orchome.com/12")]),a._v(" "),t("h6",{attrs:{id:"常规配置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#常规配置","aria-hidden":"true"}},[a._v("#")]),a._v(" 常规配置")]),a._v(" "),t("p",[a._v("这些参数是 kafka 中最基本的配置")]),a._v(" "),t("ul",[t("li",[a._v("broker.id")])]),a._v(" "),t("p",[a._v("每个 broker 都需要有一个标识符，使用 broker.id 来表示。它的默认值是 0，它可以被设置成其他任意整数，在集群中需要保证每个节点的 broker.id 都是唯一的。")]),a._v(" "),t("ul",[t("li",[a._v("port")])]),a._v(" "),t("p",[a._v("如果使用配置样本来启动 kafka ，它会监听 9092 端口，修改 port 配置参数可以把它设置成其他任意可用的端口。")]),a._v(" "),t("ul",[t("li",[a._v("zookeeper.connect")])]),a._v(" "),t("p",[a._v("用于保存 broker 元数据的地址是通过 zookeeper.connect 来指定。localhost:2181 表示运行在本地 2181 端口。该配置参数是用逗号分隔的一组 hostname:port/path 列表，每一部分含义如下：")]),a._v(" "),t("p",[a._v("hostname 是 zookeeper 服务器的服务名或 IP 地址")]),a._v(" "),t("p",[a._v("port 是 zookeeper 连接的端口")]),a._v(" "),t("p",[a._v("/path 是可选的 zookeeper 路径，作为 Kafka 集群的 chroot 环境。如果不指定，默认使用跟路径")]),a._v(" "),t("ul",[t("li",[a._v("log.dirs")])]),a._v(" "),t("p",[a._v("Kafka 把消息都保存在磁盘上，存放这些日志片段的目录都是通过 "),t("code",[a._v("log.dirs")]),a._v(' 来指定的。它是一组用逗号分隔的本地文件系统路径。如果指定了多个路径，那么 broker 会根据 "最少使用" 原则，把同一分区的日志片段保存到同一路径下。要注意，broker 会向拥有最少数目分区的路径新增分区，而不是向拥有最小磁盘空间的路径新增分区。')]),a._v(" "),t("ul",[t("li",[a._v("num.recovery.threads.per.data.dir")])]),a._v(" "),t("p",[a._v("对于如下 3 种情况，Kafka 会使用可配置的线程池来处理日志片段")]),a._v(" "),t("p",[a._v("服务器正常启动，用于打开每个分区的日志片段；")]),a._v(" "),t("p",[a._v("服务器崩溃后启动，用于检查和截断每个分区的日志片段；")]),a._v(" "),t("p",[a._v("服务器正常关闭，用于关闭日志片段")]),a._v(" "),t("p",[a._v("默认情况下，每个日志目录只使用一个线程。因为这些线程只是在服务器启动和关闭时会用到，所以完全可以设置大量的线程来达到井行操作的目的。特别是对于包含大量分区的服务器来说，一旦发生崩愤，在进行恢复时使用井行操作可能会省下数小时的时间。设置此参数时需要注意，所配置的数字对应的是 log.dirs 指定的单个日志目录。也就是说，如果 num.recovery.threads.per.data.dir 被设为 8，并且 log.dir 指定了 3 个路径，那么总共需要 24 个线程。")]),a._v(" "),t("ul",[t("li",[a._v("auto.create.topics.enable")])]),a._v(" "),t("p",[a._v("默认情况下，Kafka 会在如下 3 种情况下创建主题")]),a._v(" "),t("p",[a._v("当一个生产者开始往主题写入消息时")]),a._v(" "),t("p",[a._v("当一个消费者开始从主题读取消息时")]),a._v(" "),t("p",[a._v("当任意一个客户向主题发送元数据请求时")]),a._v(" "),t("ul",[t("li",[a._v("delete.topic.enable")])]),a._v(" "),t("p",[a._v("如果你想要删除一个主题，你可以使用主题管理工具。默认情况下，是不允许删除主题的，delete.topic.enable 的默认值是 false 因此你不能随意删除主题。这是对生产环境的合理性保护，但是在开发环境和测试环境，是可以允许你删除主题的，所以，如果你想要删除主题，需要把 delete.topic.enable 设为 true。")]),a._v(" "),t("h3",{attrs:{id:"主题默认配置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#主题默认配置","aria-hidden":"true"}},[a._v("#")]),a._v(" 主题默认配置")]),a._v(" "),t("p",[a._v("Kafka 为新创建的主题提供了很多默认配置参数，下面就来一起认识一下这些参数")]),a._v(" "),t("ul",[t("li",[a._v("num.partitions")])]),a._v(" "),t("p",[a._v("num.partitions 参数指定了新创建的主题需要包含多少个分区。如果启用了主题自动创建功能（该功能是默认启用的），主题分区的个数就是该参数指定的值。该参数的默认值是 1。要注意，我们可以增加主题分区的个数，但不能减少分区的个数。")]),a._v(" "),t("ul",[t("li",[a._v("default.replication.factor")])]),a._v(" "),t("p",[a._v("这个参数比较简单，它表示 kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务default.replication.factor 的默认值为1，这个参数在你启用了主题自动创建功能后有效。")]),a._v(" "),t("ul",[t("li",[t("strong",[a._v("log.retention.ms")])])]),a._v(" "),t("p",[a._v("Kafka 通常根据时间来决定数据可以保留多久。默认使用 log.retention.hours 参数来配置时间，默认是 168 个小时，也就是一周。除此之外，还有两个参数 log.retention.minutes 和 log.retentiion.ms 。这三个参数作用是一样的，都是决定消息多久以后被删除，推荐使用 log.retention.ms。")]),a._v(" "),t("ul",[t("li",[t("strong",[a._v("log.retention.bytes")])])]),a._v(" "),t("p",[a._v("另一种保留消息的方式是判断消息是否过期。它的值通过参数 "),t("code",[a._v("log.retention.bytes")]),a._v(" 来指定，作用在每一个分区上。也就是说，如果有一个包含 8 个分区的主题，并且 log.retention.bytes 被设置为 1GB，那么这个主题最多可以保留 8GB 数据。所以，当主题的分区个数增加时，整个主题可以保留的数据也随之增加。")]),a._v(" "),t("ul",[t("li",[a._v("log.segment.bytes")])]),a._v(" "),t("p",[a._v("上述的日志都是作用在日志片段上，而不是作用在单个消息上。当消息到达 broker 时，它们被追加到分区的当前日志片段上，当日志片段大小到达 log.segment.bytes 指定上限（默认为 1GB）时，当前日志片段就会被关闭，一个新的日志片段被打开。如果一个日志片段被关闭，就开始等待过期。这个参数的值越小，就越会频繁的关闭和分配新文件，从而降低磁盘写入的整体效率。")]),a._v(" "),t("ul",[t("li",[a._v("log.segment.ms")])]),a._v(" "),t("p",[a._v("上面提到日志片段经关闭后需等待过期，那么 "),t("code",[a._v("log.segment.ms")]),a._v(" 这个参数就是指定日志多长时间被关闭的参数和，log.segment.ms 和 log.retention.bytes 也不存在互斥问题。日志片段会在大小或时间到达上限时被关闭，就看哪个条件先得到满足。")]),a._v(" "),t("ul",[t("li",[a._v("message.max.bytes")])]),a._v(" "),t("p",[a._v("broker 通过设置 "),t("code",[a._v("message.max.bytes")]),a._v(" 参数来限制单个消息的大小，默认是 1000 000， 也就是 1MB，如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会收到 broker 返回的错误消息。跟其他与字节相关的配置参数一样，该参数指的是压缩后的消息大小，也就是说，只要压缩后的消息小于 mesage.max.bytes，那么消息的实际大小可以大于这个值")]),a._v(" "),t("p",[a._v("这个值对性能有显著的影响。值越大，那么负责处理网络连接和请求的线程就需要花越多的时间来处理这些请求。它还会增加磁盘写入块的大小，从而影响 IO 吞吐量。")]),a._v(" "),t("h3",{attrs:{id:"维护-kafka-消费者信息"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#维护-kafka-消费者信息","aria-hidden":"true"}},[a._v("#")]),a._v(" 维护 kafka 消费者信息")]),a._v(" "),t("p",[a._v("kafka 中有一个队列 __consumer_offsets 默认没有副本，一旦数据有问题就会导致分区消费不平均、消费不下去、分区不消费等各种奇怪问题。下面是给这个 topic 增加副本并 assignment 分配好。kafka-manager 没法直接没有副本的topic。")]),a._v(" "),t("p",[a._v("生成相关 json 信息字符脚本，注意新增 id 这个文件，里面放 brokerId，每个换行。")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token for-or-select variable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("`")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("seq")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("49")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("`")])]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 49表示__consumer_offsets topic的分区数-1")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("do")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("while")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("do")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("NUM1")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("`")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("expr")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("$RANDOM")]),a._v(" % "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("11")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("`")])]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#11表示kafka节点数+1")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("if")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$NUM1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("then")]),a._v("\n       "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("while")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("do")]),a._v("\n                "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("NUM2")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("`")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("expr")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("$RANDOM")]),a._v(" % "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("11")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("`")])]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#11表示kafka节点数+1")]),a._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("if")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$NUM1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$NUM2")]),a._v(" -o "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$NUM2")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("then")]),a._v("\n         "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("continue")]),a._v("\n     "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("else")]),a._v("\n         "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("break")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("fi")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("done")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("break")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("else")]),a._v("\n          "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("continue")]),a._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("fi")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("done")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("echo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('\'{"topic":"__consumer_offsets","partition":\'')]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$a")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v("',\"replicas\":['")]),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("`")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("sed")]),a._v(" -n $"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("NUM1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("p "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("id")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("`")])]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v("','")]),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("`")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("sed")]),a._v(" -n $"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("NUM2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("p "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("id")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("`")])]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v("']},'")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#新增id这个文件，文件内容为broker的id")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("done")]),a._v("\n")])])]),t("p",[a._v("生成后新建文件 increase-replication-factor.json")]),a._v(" "),t("div",{staticClass:"language-json extra-class"},[t("pre",{pre:!0,attrs:{class:"language-json"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),t("span",{pre:!0,attrs:{class:"token property"}},[a._v('"version"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token property"}},[a._v('"partitions"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("\n# 粘贴刚才生成的字符串，去掉最后逗号\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n")])])]),t("p",[a._v("执行命令")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("/data/kafka/bin/kafka-reassign-partitions.sh --zookeeper "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("192.168")]),a._v(".100.31:2181 --reassignment-json-file increase-replication-factor.json --execute\n")])])])])}),[],!1,null,null,null);s.default=r.exports}}]);